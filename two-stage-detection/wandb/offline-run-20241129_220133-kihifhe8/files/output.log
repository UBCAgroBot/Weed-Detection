[11/29 22:01:37 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)
    )
  )
)
WARNING [11/29 22:01:37 d2.data.datasets.coco]:
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.
[11/29 22:01:37 d2.data.datasets.coco]: Loaded 1661 images in COCO format from ../datasets/Annotated-Images-for-Automated-Weed-Identification-and-Management/train/_annotations.coco.json
[11/29 22:01:37 d2.data.build]: Removed 6 images with no usable annotations. 1655 images left.
[11/29 22:01:37 d2.data.build]: Distribution of instances among all 2 categories:
|  category   | #instances   |   category    | #instances   |
|:-----------:|:-------------|:-------------:|:-------------|
| grass-weeds | 0            | 0 ridderzur.. | 4199         |
|             |              |               |              |
|    total    | 4199         |               |              |
[11/29 22:01:37 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/29 22:01:37 d2.data.build]: Using training sampler TrainingSampler
[11/29 22:01:37 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/29 22:01:37 d2.data.common]: Serializing 1655 elements to byte tensors and concatenating them all ...
[11/29 22:01:37 d2.data.common]: Serialized dataset takes 0.65 MiB
[11/29 22:01:37 d2.data.build]: Making batched data loader with batch_size=2
WARNING [11/29 22:01:37 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[11/29 22:01:37 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./pretrained_weights/model_final_68b088.pkl ...
[11/29 22:01:37 d2.engine.train_loop]: Starting training from iteration 0
[11/29 22:06:19 d2.utils.events]:  eta: 4:37:23  iter: 19  total_loss: 1.69  loss_cls: 1.215  loss_box_reg: 0.1662  loss_rpn_cls: 0.3136  loss_rpn_loc: 0.01666    time: 13.8701  last_time: 11.9832  data_time: 0.0191  last_data_time: 0.0055   lr: 4.9953e-06  max_mem: 0M
[11/29 22:11:06 d2.utils.events]:  eta: 4:35:39  iter: 39  total_loss: 1.633  loss_cls: 0.9759  loss_box_reg: 0.2295  loss_rpn_cls: 0.4253  loss_rpn_loc: 0.02323    time: 14.1112  last_time: 15.2960  data_time: 0.0059  last_data_time: 0.0047   lr: 9.9902e-06  max_mem: 0M
[11/29 22:15:40 d2.utils.events]:  eta: 4:23:07  iter: 59  total_loss: 1.16  loss_cls: 0.6732  loss_box_reg: 0.2182  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.01284    time: 13.9685  last_time: 13.4201  data_time: 0.0051  last_data_time: 0.0048   lr: 1.4985e-05  max_mem: 0M
[11/29 22:20:17 d2.utils.events]:  eta: 4:21:31  iter: 79  total_loss: 1.077  loss_cls: 0.4816  loss_box_reg: 0.3098  loss_rpn_cls: 0.1974  loss_rpn_loc: 0.0217    time: 13.9456  last_time: 12.6458  data_time: 0.0051  last_data_time: 0.0063   lr: 1.998e-05  max_mem: 0M
[11/29 22:24:58 d2.utils.events]:  eta: 4:16:51  iter: 99  total_loss: 0.9696  loss_cls: 0.3613  loss_box_reg: 0.3066  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.02106    time: 13.9589  last_time: 14.4806  data_time: 0.0055  last_data_time: 0.0059   lr: 2.4975e-05  max_mem: 0M
[11/29 22:29:37 d2.utils.events]:  eta: 4:14:08  iter: 119  total_loss: 0.6368  loss_cls: 0.2819  loss_box_reg: 0.2545  loss_rpn_cls: 0.09368  loss_rpn_loc: 0.01265    time: 13.9610  last_time: 15.1267  data_time: 0.0053  last_data_time: 0.0057   lr: 2.997e-05  max_mem: 0M
[11/29 22:34:15 d2.utils.events]:  eta: 4:08:22  iter: 139  total_loss: 0.7396  loss_cls: 0.2815  loss_box_reg: 0.3048  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.01544    time: 13.9486  last_time: 15.6120  data_time: 0.0050  last_data_time: 0.0052   lr: 3.4965e-05  max_mem: 0M
[11/29 22:38:56 d2.utils.events]:  eta: 4:04:42  iter: 159  total_loss: 0.8906  loss_cls: 0.2941  loss_box_reg: 0.3636  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.02423    time: 13.9612  last_time: 11.8429  data_time: 0.0052  last_data_time: 0.0094   lr: 3.996e-05  max_mem: 0M
[11/29 22:43:26 d2.utils.events]:  eta: 3:57:56  iter: 179  total_loss: 0.6836  loss_cls: 0.239  loss_box_reg: 0.306  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.01222    time: 13.9105  last_time: 12.2169  data_time: 0.0050  last_data_time: 0.0055   lr: 4.4955e-05  max_mem: 0M
[11/29 22:48:08 d2.utils.events]:  eta: 3:54:20  iter: 199  total_loss: 0.5842  loss_cls: 0.2391  loss_box_reg: 0.2952  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.01229    time: 13.9288  last_time: 12.2341  data_time: 0.0052  last_data_time: 0.0048   lr: 4.995e-05  max_mem: 0M
[11/29 22:52:32 d2.utils.events]:  eta: 3:48:25  iter: 219  total_loss: 0.5269  loss_cls: 0.2021  loss_box_reg: 0.2407  loss_rpn_cls: 0.03064  loss_rpn_loc: 0.01836    time: 13.8656  last_time: 13.0980  data_time: 0.0051  last_data_time: 0.0048   lr: 5.4945e-05  max_mem: 0M
[11/29 22:56:59 d2.utils.events]:  eta: 3:41:57  iter: 239  total_loss: 0.5547  loss_cls: 0.1916  loss_box_reg: 0.2711  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.01211    time: 13.8211  last_time: 14.7753  data_time: 0.0050  last_data_time: 0.0047   lr: 5.994e-05  max_mem: 0M
[11/29 23:01:19 d2.utils.events]:  eta: 3:35:59  iter: 259  total_loss: 0.3989  loss_cls: 0.1254  loss_box_reg: 0.1934  loss_rpn_cls: 0.0213  loss_rpn_loc: 0.01176    time: 13.7554  last_time: 10.9427  data_time: 0.0048  last_data_time: 0.0047   lr: 6.4935e-05  max_mem: 0M
[11/29 23:05:38 d2.utils.events]:  eta: 3:29:10  iter: 279  total_loss: 0.4523  loss_cls: 0.1378  loss_box_reg: 0.2262  loss_rpn_cls: 0.03271  loss_rpn_loc: 0.009399    time: 13.6971  last_time: 13.3043  data_time: 0.0050  last_data_time: 0.0048   lr: 6.993e-05  max_mem: 0M
[11/29 23:10:07 d2.utils.events]:  eta: 3:24:26  iter: 299  total_loss: 0.4243  loss_cls: 0.1355  loss_box_reg: 0.2504  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.009248    time: 13.6822  last_time: 14.3413  data_time: 0.0051  last_data_time: 0.0047   lr: 7.4925e-05  max_mem: 0M
[11/29 23:14:34 d2.utils.events]:  eta: 3:19:40  iter: 319  total_loss: 0.5564  loss_cls: 0.1776  loss_box_reg: 0.3564  loss_rpn_cls: 0.01014  loss_rpn_loc: 0.01006    time: 13.6623  last_time: 13.5882  data_time: 0.0048  last_data_time: 0.0047   lr: 7.992e-05  max_mem: 0M
[11/29 23:18:55 d2.utils.events]:  eta: 3:14:57  iter: 339  total_loss: 0.458  loss_cls: 0.135  loss_box_reg: 0.2864  loss_rpn_cls: 0.009721  loss_rpn_loc: 0.01174    time: 13.6235  last_time: 14.5240  data_time: 0.0048  last_data_time: 0.0047   lr: 8.4915e-05  max_mem: 0M
[11/29 23:23:15 d2.utils.events]:  eta: 3:10:16  iter: 359  total_loss: 0.5814  loss_cls: 0.1399  loss_box_reg: 0.3291  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.01522    time: 13.5892  last_time: 10.0738  data_time: 0.0050  last_data_time: 0.0062   lr: 8.991e-05  max_mem: 0M
[11/29 23:27:43 d2.utils.events]:  eta: 3:06:00  iter: 379  total_loss: 0.4961  loss_cls: 0.1261  loss_box_reg: 0.2919  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.01484    time: 13.5800  last_time: 14.6679  data_time: 0.0050  last_data_time: 0.0054   lr: 9.4905e-05  max_mem: 0M
[11/29 23:32:05 d2.utils.events]:  eta: 3:01:27  iter: 399  total_loss: 0.4298  loss_cls: 0.1405  loss_box_reg: 0.247  loss_rpn_cls: 0.02243  loss_rpn_loc: 0.01285    time: 13.5559  last_time: 13.1294  data_time: 0.0049  last_data_time: 0.0047   lr: 9.99e-05  max_mem: 0M
[11/29 23:36:37 d2.utils.events]:  eta: 2:56:57  iter: 419  total_loss: 0.4519  loss_cls: 0.1247  loss_box_reg: 0.293  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01284    time: 13.5581  last_time: 14.8400  data_time: 0.0053  last_data_time: 0.0049   lr: 0.0001049  max_mem: 0M
[11/29 23:41:02 d2.utils.events]:  eta: 2:52:27  iter: 439  total_loss: 0.4392  loss_cls: 0.1027  loss_box_reg: 0.2736  loss_rpn_cls: 0.03385  loss_rpn_loc: 0.009772    time: 13.5443  last_time: 14.1693  data_time: 0.0049  last_data_time: 0.0046   lr: 0.00010989  max_mem: 0M
[11/29 23:45:45 d2.utils.events]:  eta: 2:48:11  iter: 459  total_loss: 0.3483  loss_cls: 0.09801  loss_box_reg: 0.2204  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.0115    time: 13.5694  last_time: 14.0452  data_time: 0.0052  last_data_time: 0.0044   lr: 0.00011489  max_mem: 0M
[11/29 23:50:23 d2.utils.events]:  eta: 2:43:44  iter: 479  total_loss: 0.4048  loss_cls: 0.1107  loss_box_reg: 0.2878  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.01048    time: 13.5832  last_time: 11.3253  data_time: 0.0053  last_data_time: 0.0048   lr: 0.00011988  max_mem: 0M
[11/29 23:54:56 d2.utils.events]:  eta: 2:39:29  iter: 499  total_loss: 0.408  loss_cls: 0.1245  loss_box_reg: 0.2579  loss_rpn_cls: 0.008335  loss_rpn_loc: 0.01328    time: 13.5857  last_time: 12.4542  data_time: 0.0050  last_data_time: 0.0048   lr: 0.00012488  max_mem: 0M
[11/29 23:59:31 d2.utils.events]:  eta: 2:35:17  iter: 519  total_loss: 0.4755  loss_cls: 0.1314  loss_box_reg: 0.2936  loss_rpn_cls: 0.02034  loss_rpn_loc: 0.01496    time: 13.5920  last_time: 14.2370  data_time: 0.0049  last_data_time: 0.0046   lr: 0.00012987  max_mem: 0M
[11/30 00:04:09 d2.utils.events]:  eta: 2:30:51  iter: 539  total_loss: 0.4489  loss_cls: 0.1333  loss_box_reg: 0.235  loss_rpn_cls: 0.02638  loss_rpn_loc: 0.01706    time: 13.6040  last_time: 14.3494  data_time: 0.0053  last_data_time: 0.0048   lr: 0.00013487  max_mem: 0M
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
/home/nlin06/miniconda3/envs/two-stage-weed/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in ./output
[11/30 00:08:42 d2.utils.events]:  eta: 2:26:27  iter: 559  total_loss: 0.5126  loss_cls: 0.1367  loss_box_reg: 0.2699  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.01306    time: 13.6059  last_time: 14.2915  data_time: 0.0051  last_data_time: 0.0047   lr: 0.00013986  max_mem: 0M
[11/30 00:13:16 d2.utils.events]:  eta: 2:22:43  iter: 579  total_loss: 0.431  loss_cls: 0.1262  loss_box_reg: 0.2211  loss_rpn_cls: 0.04885  loss_rpn_loc: 0.01861    time: 13.6079  last_time: 14.9342  data_time: 0.0050  last_data_time: 0.0047   lr: 0.00014486  max_mem: 0M
[11/30 00:17:41 d2.utils.events]:  eta: 2:18:09  iter: 599  total_loss: 0.2914  loss_cls: 0.09076  loss_box_reg: 0.167  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.008545    time: 13.5970  last_time: 12.9174  data_time: 0.0050  last_data_time: 0.0049   lr: 0.00014985  max_mem: 0M
[11/30 00:22:09 d2.utils.events]:  eta: 2:13:31  iter: 619  total_loss: 0.5253  loss_cls: 0.1524  loss_box_reg: 0.2974  loss_rpn_cls: 0.03377  loss_rpn_loc: 0.02502    time: 13.5897  last_time: 11.7012  data_time: 0.0051  last_data_time: 0.0063   lr: 0.00015485  max_mem: 0M
[11/30 00:26:45 d2.utils.events]:  eta: 2:09:05  iter: 639  total_loss: 0.2881  loss_cls: 0.08742  loss_box_reg: 0.1742  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.01032    time: 13.5965  last_time: 15.0181  data_time: 0.0050  last_data_time: 0.0053   lr: 0.00015984  max_mem: 0M
[11/30 00:31:24 d2.utils.events]:  eta: 2:04:45  iter: 659  total_loss: 0.3649  loss_cls: 0.1187  loss_box_reg: 0.1935  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.01362    time: 13.6072  last_time: 12.1680  data_time: 0.0051  last_data_time: 0.0046   lr: 0.00016484  max_mem: 0M
[11/30 00:35:57 d2.utils.events]:  eta: 2:00:05  iter: 679  total_loss: 0.3375  loss_cls: 0.1077  loss_box_reg: 0.1923  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.01212    time: 13.6089  last_time: 14.9986  data_time: 0.0048  last_data_time: 0.0047   lr: 0.00016983  max_mem: 0M
[11/30 00:40:28 d2.utils.events]:  eta: 1:55:28  iter: 699  total_loss: 0.3742  loss_cls: 0.1306  loss_box_reg: 0.2164  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.01642    time: 13.6067  last_time: 13.9726  data_time: 0.0051  last_data_time: 0.0047   lr: 0.00017483  max_mem: 0M
[11/30 00:44:53 d2.utils.events]:  eta: 1:50:51  iter: 719  total_loss: 0.3433  loss_cls: 0.09324  loss_box_reg: 0.1958  loss_rpn_cls: 0.0261  loss_rpn_loc: 0.009805    time: 13.5974  last_time: 14.9118  data_time: 0.0050  last_data_time: 0.0048   lr: 0.00017982  max_mem: 0M
[11/30 00:49:34 d2.utils.events]:  eta: 1:46:18  iter: 739  total_loss: 0.3775  loss_cls: 0.1222  loss_box_reg: 0.2322  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.01099    time: 13.6098  last_time: 15.0397  data_time: 0.0050  last_data_time: 0.0047   lr: 0.00018482  max_mem: 0M
[11/30 00:54:08 d2.utils.events]:  eta: 1:41:45  iter: 759  total_loss: 0.4525  loss_cls: 0.1352  loss_box_reg: 0.2415  loss_rpn_cls: 0.009328  loss_rpn_loc: 0.0157    time: 13.6110  last_time: 12.4259  data_time: 0.0052  last_data_time: 0.0045   lr: 0.00018981  max_mem: 0M
[11/30 00:58:28 d2.utils.events]:  eta: 1:37:02  iter: 779  total_loss: 0.3487  loss_cls: 0.1146  loss_box_reg: 0.2259  loss_rpn_cls: 0.00734  loss_rpn_loc: 0.01024    time: 13.5953  last_time: 13.0786  data_time: 0.0051  last_data_time: 0.0064   lr: 0.00019481  max_mem: 0M
[11/30 01:03:08 d2.utils.events]:  eta: 1:32:28  iter: 799  total_loss: 0.4703  loss_cls: 0.1416  loss_box_reg: 0.2397  loss_rpn_cls: 0.02661  loss_rpn_loc: 0.01554    time: 13.6060  last_time: 14.1889  data_time: 0.0050  last_data_time: 0.0046   lr: 0.0001998  max_mem: 0M
[11/30 01:07:44 d2.utils.events]:  eta: 1:27:53  iter: 819  total_loss: 0.3992  loss_cls: 0.1181  loss_box_reg: 0.2608  loss_rpn_cls: 0.02997  loss_rpn_loc: 0.01653    time: 13.6110  last_time: 14.9552  data_time: 0.0052  last_data_time: 0.0054   lr: 0.0002048  max_mem: 0M
[11/30 01:12:15 d2.utils.events]:  eta: 1:23:15  iter: 839  total_loss: 0.4428  loss_cls: 0.116  loss_box_reg: 0.2471  loss_rpn_cls: 0.02026  loss_rpn_loc: 0.01634    time: 13.6089  last_time: 14.3186  data_time: 0.0055  last_data_time: 0.0047   lr: 0.00020979  max_mem: 0M
[11/30 01:16:52 d2.utils.events]:  eta: 1:18:40  iter: 859  total_loss: 0.4435  loss_cls: 0.1165  loss_box_reg: 0.2452  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.01662    time: 13.6148  last_time: 15.1583  data_time: 0.0053  last_data_time: 0.0054   lr: 0.00021479  max_mem: 0M
[11/30 01:21:27 d2.utils.events]:  eta: 1:14:01  iter: 879  total_loss: 0.2968  loss_cls: 0.08621  loss_box_reg: 0.1903  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.01148    time: 13.6180  last_time: 14.9117  data_time: 0.0049  last_data_time: 0.0047   lr: 0.00021978  max_mem: 0M
[11/30 01:25:52 d2.utils.events]:  eta: 1:09:23  iter: 899  total_loss: 0.368  loss_cls: 0.1272  loss_box_reg: 0.2094  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.01413    time: 13.6101  last_time: 14.9027  data_time: 0.0049  last_data_time: 0.0047   lr: 0.00022478  max_mem: 0M
[11/30 01:30:24 d2.utils.events]:  eta: 1:04:43  iter: 919  total_loss: 0.3524  loss_cls: 0.1232  loss_box_reg: 0.2178  loss_rpn_cls: 0.01677  loss_rpn_loc: 0.02072    time: 13.6091  last_time: 12.2048  data_time: 0.0048  last_data_time: 0.0047   lr: 0.00022977  max_mem: 0M
[11/30 01:34:57 d2.utils.events]:  eta: 1:00:08  iter: 939  total_loss: 0.3787  loss_cls: 0.1173  loss_box_reg: 0.1983  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.01344    time: 13.6106  last_time: 11.4588  data_time: 0.0050  last_data_time: 0.0046   lr: 0.00023477  max_mem: 0M
[11/30 01:39:35 d2.utils.events]:  eta: 0:55:32  iter: 959  total_loss: 0.3029  loss_cls: 0.1021  loss_box_reg: 0.1781  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.0129    time: 13.6165  last_time: 14.1158  data_time: 0.0051  last_data_time: 0.0046   lr: 0.00023976  max_mem: 0M
[11/30 01:44:13 d2.utils.events]:  eta: 0:50:56  iter: 979  total_loss: 0.3964  loss_cls: 0.1324  loss_box_reg: 0.2088  loss_rpn_cls: 0.01921  loss_rpn_loc: 0.01679    time: 13.6225  last_time: 14.8929  data_time: 0.0051  last_data_time: 0.0055   lr: 0.00024476  max_mem: 0M
[11/30 01:48:52 d2.utils.events]:  eta: 0:46:22  iter: 999  total_loss: 0.4008  loss_cls: 0.1296  loss_box_reg: 0.2107  loss_rpn_cls: 0.03101  loss_rpn_loc: 0.01436    time: 13.6282  last_time: 14.9334  data_time: 0.0049  last_data_time: 0.0046   lr: 0.00024975  max_mem: 0M
[11/30 01:53:25 d2.utils.events]:  eta: 0:41:40  iter: 1019  total_loss: 0.4095  loss_cls: 0.1216  loss_box_reg: 0.2385  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01367    time: 13.6294  last_time: 14.8311  data_time: 0.0051  last_data_time: 0.0057   lr: 0.00025  max_mem: 0M
[11/30 01:57:54 d2.utils.events]:  eta: 0:37:01  iter: 1039  total_loss: 0.4323  loss_cls: 0.1249  loss_box_reg: 0.2354  loss_rpn_cls: 0.03745  loss_rpn_loc: 0.01603    time: 13.6253  last_time: 11.6117  data_time: 0.0053  last_data_time: 0.0051   lr: 0.00025  max_mem: 0M
[11/30 02:02:26 d2.utils.events]:  eta: 0:32:25  iter: 1059  total_loss: 0.3778  loss_cls: 0.1151  loss_box_reg: 0.2057  loss_rpn_cls: 0.02461  loss_rpn_loc: 0.01315    time: 13.6249  last_time: 11.6769  data_time: 0.0053  last_data_time: 0.0046   lr: 0.00025  max_mem: 0M
[11/30 02:07:02 d2.utils.events]:  eta: 0:27:46  iter: 1079  total_loss: 0.3194  loss_cls: 0.103  loss_box_reg: 0.1917  loss_rpn_cls: 0.009186  loss_rpn_loc: 0.01072    time: 13.6282  last_time: 12.6111  data_time: 0.0051  last_data_time: 0.0047   lr: 0.00025  max_mem: 0M
[11/30 02:11:34 d2.utils.events]:  eta: 0:23:09  iter: 1099  total_loss: 0.2808  loss_cls: 0.1077  loss_box_reg: 0.1494  loss_rpn_cls: 0.01891  loss_rpn_loc: 0.01174    time: 13.6281  last_time: 14.8981  data_time: 0.0048  last_data_time: 0.0053   lr: 0.00025  max_mem: 0M
[11/30 02:16:09 d2.utils.events]:  eta: 0:18:31  iter: 1119  total_loss: 0.3964  loss_cls: 0.1163  loss_box_reg: 0.2175  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.01275    time: 13.6300  last_time: 15.0141  data_time: 0.0048  last_data_time: 0.0045   lr: 0.00025  max_mem: 0M
[11/30 02:20:46 d2.utils.events]:  eta: 0:13:55  iter: 1139  total_loss: 0.3627  loss_cls: 0.1315  loss_box_reg: 0.1847  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.009354    time: 13.6340  last_time: 12.4162  data_time: 0.0050  last_data_time: 0.0048   lr: 0.00025  max_mem: 0M
[11/30 02:25:41 d2.utils.events]:  eta: 0:09:18  iter: 1159  total_loss: 0.3305  loss_cls: 0.1135  loss_box_reg: 0.1943  loss_rpn_cls: 0.02352  loss_rpn_loc: 0.008439    time: 13.6529  last_time: 15.3237  data_time: 0.0051  last_data_time: 0.0047   lr: 0.00025  max_mem: 0M
[11/30 02:30:22 d2.utils.events]:  eta: 0:04:39  iter: 1179  total_loss: 0.3636  loss_cls: 0.09432  loss_box_reg: 0.1991  loss_rpn_cls: 0.03419  loss_rpn_loc: 0.009202    time: 13.6598  last_time: 14.3039  data_time: 0.0053  last_data_time: 0.0051   lr: 0.00025  max_mem: 0M
[11/30 02:34:51 d2.utils.events]:  eta: 0:00:00  iter: 1199  total_loss: 0.251  loss_cls: 0.07553  loss_box_reg: 0.1489  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.006482    time: 13.6551  last_time: 13.1930  data_time: 0.0052  last_data_time: 0.0045   lr: 0.00025  max_mem: 0M
[11/30 02:34:51 d2.engine.hooks]: Overall training speed: 1198 iterations in 4:32:38 (13.6551 s / it)
[11/30 02:34:51 d2.engine.hooks]: Total training time: 4:32:41 (0:00:02 on hooks)
WARNING [11/30 02:34:51 d2.data.datasets.coco]:
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.
[11/30 02:34:51 d2.data.datasets.coco]: Loaded 245 images in COCO format from ../datasets/Annotated-Images-for-Automated-Weed-Identification-and-Management/test/_annotations.coco.json
[11/30 02:34:51 d2.data.build]: Distribution of instances among all 2 categories:
|  category   | #instances   |   category    | #instances   |
|:-----------:|:-------------|:-------------:|:-------------|
| grass-weeds | 0            | 0 ridderzur.. | 662          |
|             |              |               |              |
|    total    | 662          |               |              |
[11/30 02:34:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/30 02:34:51 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/30 02:34:51 d2.data.common]: Serializing 245 elements to byte tensors and concatenating them all ...
[11/30 02:34:51 d2.data.common]: Serialized dataset takes 0.10 MiB
WARNING [11/30 02:34:51 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.